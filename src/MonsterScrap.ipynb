{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonsterScrap doc\n",
    "These functions allow you to perform web scrapping on the Monster platform, to collect job detail.\n",
    "____\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, HTTPError\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapBody()* function allows to take the body part of an html document from the URL.\n",
    "\n",
    "This is to avoid redundant code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapBody(url):\n",
    "    with urlopen(url) as response:\n",
    "        body = BeautifulSoup(response.read(), 'html.parser').body\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **scrapMonsterID()** function allows to collect the *Job ID* of each job that the platform makes available.\n",
    "\n",
    "A search on Monster allows to have a complete column of jobs for the first 10 pages of results and then returns one column per page.\n",
    "\n",
    "The configuration at Monster has two modes at the end of the results:\n",
    "- Display the latest jobs posted, all categories combined, with a \"Désolé...\" message\n",
    "- Return error 404 otherwise\n",
    "\n",
    "The detection of one of these two situations marks the end of *ID* scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapMonsterID(searchList):\n",
    "    for search in searchList:\n",
    "        url = \"https://www.monster.fr/emploi/recherche/?q={}&stpage=1&page=10\".format(search)\n",
    "        body = scrapBody(url)\n",
    "        \n",
    "        sections = body.find_all('section', class_=\"card-content\")\n",
    "        sections = [section.attrs['data-jobid'] for section in sections[1:] if 'data-jobid' in section.attrs]\n",
    "        \n",
    "        count = int(body.find_next(\"h2\", class_=\"figure\").text.strip().split()[0][1:]) # Results number\n",
    "        \n",
    "        if len(sections) < count:\n",
    "            page = 11\n",
    "            while True:\n",
    "                url = \"https://www.monster.fr/emploi/recherche/?q={}&stpage=1&page={}\".format(search, page)\n",
    "                try:\n",
    "                    body = scrapBody(url)\n",
    "                except HTTPError:\n",
    "                    break\n",
    "                else:\n",
    "                    if \"Désolé\" in body.find_next(\"h1\", class_=\"pivot\").text.strip():\n",
    "                        break\n",
    "                    else:\n",
    "                        sectionPlus = body.find_all('section', class_=\"card-content\")\n",
    "                        sectionPlus = [section.attrs['data-jobid'] for section in sectionPlus[1:] if 'data-jobid' in section.attrs]\n",
    "                        sections.extend(sectionPlus)\n",
    "                page += 1\n",
    "            sections = list(set(sections))\n",
    "        else:\n",
    "            sections = list(set(sections))\n",
    "    return sections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
