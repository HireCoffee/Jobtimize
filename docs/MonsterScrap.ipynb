{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonsterScrap doc\n",
    "These functions allow to perform web scrapping on the Monster platform, to collect job detail.\n",
    "____\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Jobtimize.rotateproxies import RotateProxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get, Timeout\n",
    "from requests.exceptions import HTTPError, ProxyError\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import islice\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "from json import loads\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapBody()* function allows to take the body part of an html document from the URL.  \n",
    "This is to avoid redundant code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapBody(url, proxy = None):\n",
    "    with get(url, proxies = proxy) as response:\n",
    "        body = BeautifulSoup(response.text, 'html.parser').body\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *idFromLink()* function allows to extract the job ID from link.\n",
    "IDs come in two different forms:\n",
    "- A series of 9 numbers\n",
    "- A string of characters xxxxxxxxxx-xxxx-xxxx-xxxx-xxxxxx-xxxxxxxxxxxx\n",
    "\n",
    "Links on Monster come in 3 different forms: \n",
    "- Pages generated with ASP including the ID, composed only by 9 digits\n",
    "- The form \\*/monster/\\* with the ID, composed by string, which is the standard form for the main site\n",
    "- \"job offer\" *(in the language of the country)* with the ID in figures at the end, which is the standard form for each sub-sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idFromLink(link):\n",
    "    if \".aspx\" in link:\n",
    "        jobID = link[-14:-5]\n",
    "    elif \"/monster/\" in link:\n",
    "        jobID = re.findall(r'monster/.+?\\?', link)[0][8:-1]\n",
    "    else:\n",
    "        jobID = link[link.rfind('/')+1:]\n",
    "    return jobID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scrapMonsterID()` function extracts the *jobIDs* for each job and country from the search results provided by Monster.\n",
    "The [monster.co.uk](https://www.monster.co.uk/internationalJobs) site has access to the main master database, unlike the sub-sites which only have access to their own country the database.\n",
    "\n",
    "A query allows to have the total match if it exists. If there are more than 5000, the division *resultCountLabel* displays \"5000+\". If there is none, the division does not appear on the page.\n",
    "\n",
    "During the page browsing, $p$ greater than 1, the site has a behavior that displays the absence of results on a page $p$ while there are some on the page $p+1$ and therefore ignores the 20 results of the page $p$. The function counts it as an error.\n",
    "\n",
    "The absence of *resultCountLabel* is not interpreted as the end of the results unless the size of the list of jobs covered is equal to (or greater than) the match minus the number of jobs ignored by the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapMonsterID(searchList, countryList, prox = False):\n",
    "    setID = set()\n",
    "    for search in searchList:\n",
    "        search = search.replace(\" \",\"+\")\n",
    "        if prox: proxies = RotateProxies()\n",
    "        proxy = None\n",
    "        for country in countryList:\n",
    "            match = 5001\n",
    "            error = 0\n",
    "            listID = set()\n",
    "            page = 1\n",
    "            while True:\n",
    "                url = \"https://www.monster.co.uk/medley?q={}&fq=countryabbrev_s%3A{}&pg={}\".format(\n",
    "                    search, country, page)\n",
    "                if page % 50 == 0 and prox: proxy = proxies.next()\n",
    "                try:\n",
    "                    body = scrapBody(url, proxy)\n",
    "                except (Timeout, ProxyError):\n",
    "                    if prox:\n",
    "                        proxy = proxies.next()\n",
    "                        continue\n",
    "                    else:\n",
    "                        break\n",
    "                except HTTPError:\n",
    "                    break\n",
    "                else:\n",
    "                    if body.find(id=\"resultCountLabel\") is None:\n",
    "                        if len(listID) == 0:\n",
    "                            break\n",
    "                        else:\n",
    "                            error += 1\n",
    "                            if len(listID) >= (match - 20 * error):\n",
    "                                break\n",
    "                            else:\n",
    "                                page += 1\n",
    "                                continue\n",
    "                    else:\n",
    "                        match = int(\n",
    "                            re.sub(\n",
    "                                \"\\D\", \"\",\n",
    "                                body.find(\n",
    "                                    id=\"resultCountLabel\").text.split()[-1]))\n",
    "                        links = [\n",
    "                            link.a.attrs['href']\n",
    "                            for link in body.find_all(\"div\", class_=\"jobTitle\")\n",
    "                        ]\n",
    "                        listID = {idFromLink(link) for link in links}\n",
    "                        page += 1\n",
    "                setID = setID.union(listID)\n",
    "    return setID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dicoFromJson()* function normalizes the data of the request response. For a *jobID*, it collects information about the ad, the company and the specificities of the job in a dictionary.\n",
    "\n",
    "- description: long description\n",
    "- country: 2-letter abbreviation of the country\n",
    "- city: full city name\n",
    "- posted: job post creation date\n",
    "- header: post title\n",
    "- company: company name\n",
    "- type: type of employment contract (employee, intern...)\n",
    "- category: job category\n",
    "- url: post url redirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicoFromJson(args):\n",
    "    jobID, proxy = args\n",
    "    url = \"https://job-openings.monster.com/v2/job/pure-json-view?jobid={}\".format(\n",
    "        jobID)\n",
    "    try:\n",
    "        query = get(url, proxy).text\n",
    "    except HTTPError:\n",
    "        return {}\n",
    "    dico = loads(\n",
    "        normalize('NFKD', query).encode('ascii', 'ignore'))\n",
    "\n",
    "    general = ((\"description\", \"jobDescription\"),\n",
    "               (\"country\", \"jobLocationCountry\"),\n",
    "               (\"city\", \"jobLocationCity\"),\n",
    "               (\"posted\", \"postedDate\"))\n",
    "    company = ((\"header\", \"companyHeader\"),\n",
    "               (\"company\", \"name\"))\n",
    "    tracks = ((\"type\", \"eVar33\"),\n",
    "              (\"category\", \"eVar28\"))\n",
    "\n",
    "    ginfo, cinfo, tinfo = {}, {}, {}\n",
    "    for g in general:\n",
    "        try:\n",
    "            ginfo[g[0]] = normalize(\n",
    "                \"NFKD\",\n",
    "                \" \".join(BeautifulSoup(dico[g[1]], 'lxml').get_text().split()))\n",
    "        except KeyError:\n",
    "            ginfo[g[0]] = \"\"\n",
    "    for c in company:\n",
    "        try:\n",
    "            cinfo[c[0]] = BeautifulSoup(dico[\"companyInfo\"][c[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            cinfo[c[0]] = \"\"\n",
    "    for t in tracks:\n",
    "        try:\n",
    "            tinfo[t[0]] = BeautifulSoup(dico[\"adobeTrackingProperties\"][t[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            tinfo[t[0]] = \"\"\n",
    "    \n",
    "    dico = {**ginfo, **cinfo, **tinfo}\n",
    "    dico[\"url\"] = \"https://job-openings.monster.co.uk/monster/{}\".format(jobID)\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MonsterScrap()`** is the main function which collects and standardizes data on the Monster site.  \n",
    "Threads are used depending on the size of the results for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonsterScrap(searchList, countryList, prox = False):\n",
    "    scraped = list()\n",
    "    setID = scrapMonsterID(searchList, countryList, prox)\n",
    "    if len(setID) < 20:\n",
    "        workers = len(setID)\n",
    "    else:\n",
    "        workers = len(setID) // 5\n",
    "    \n",
    "    if prox:\n",
    "        proxies = list(islice(RotateProxies().proxies, workers)) * len(setID)\n",
    "    else:\n",
    "        proxies = [None] * len(setID)\n",
    "    \n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        for result in executor.map(dicoFromJson, zip(setID, proxies)):\n",
    "            scraped.append(result)\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of use\n",
    "Let's do research on the data scientist post in the United Kingdom only.  \n",
    "Preview the 3rd item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"One Passion. One Culture. Endless Opportunity. At NVIDIA, our employees are passionate about Artificial Intelligence, Visual Computing and Autonomous vehicles. We're united in our quest to transform the way GPUs are used for work and play. Our technology impacts the visual experience in video game development, film production, space exploration, medicine, computational finance and automotive design to name a few, and we've only scratched the surface of what we can accomplish when we apply our technology to it. We need passionate, hard-working and creative people to help us seek some of these unrivaled opportunities.At NVIDIA, we work, think and learn as a team. We thrive in a deeply strong environment and we're passionate about a culture that demands innovation and the highest standards. The rewards are sweet and include collaborating with some of the smartest people in the industry, an aggressive compensation plan that rewards top performers, and the opportunity to work on products that transform the way people work and play.We are looking for an EMEA Sales Leader Financial Services and Fintech.What youll be doing: Youll be working in the most exciting & dynamic area of technology that exists today, driving the adoption of AI & Deep LearningBuilding strategic relationships with the EMEA Financial Services ecosystem including global banks, insurers, startups, software & consulting companies, manufacturers and resellers.Working across all major internal functional areas (engineering, sales, marketing, executives), as well as external partners, customers, developers & data scientistsWorking with OEM & reseller partners that are also directly engaged with the FSI communityContinuously building and refining a strategic plan for developing the European go to market in FSI, where do we focus and how do we scaleSegment and size markets while prioritizing them for AI adoption rate and impactDrive short and long-term revenue opportunitiesForecast & deliver revenue goals according to the aboveOwn strategic accounts to develop the market: proof of concepts, roadmap reviews, technology solution designEnable the extended sales team to sell into like customers and achieve revenue growthBe a contributor to high profile industry events & meetupsSupport product development by demonstrating a virtual team of technical resources to establish early customers success as well as deep understanding of technology used and neededContinuously look for opportunities to showcase customer success by working with marketing to package up success stories, participate in launches and events.Develop trust-based relationships with key partner personnel, including senior executive management.What we need to see Deep knowledge & network in Financial Services and associated technologyAn understanding of AI and how it is/will be applied to FSIPassion for ecosystem developmentStartup mentality, accountability and comfort working in a fast paced, open culture.Successful track record in building a sales focused businessExcellent interpersonal skillsDemonstration of working across all internal business functions (engineering, sales, marketing exec)Ways to stand out from the crowd:Previous experience in AI / Deep Learning / Machine LearningKnowledge of data science or associated degreeEuropean LanguagesNVIDIA has continuously reinvented itself over two decades.NVIDIAs invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined modern computer graphics, and revolutionized parallel computing. More recently, GPU deep learning ignited modern AI the next era of computing with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world.This is our lifes work to amplify human imagination and intelligence.With highly competitive salaries and a comprehensive benefits package, NVIDIA is widely considered to be one of the technology worlds most desirable employers. We have some of the most brilliant and talented people in the world working for us and, due to extraordinary growth, our elite teams are growing fast. If you're a creative and autonomous manager with a real passion for technology, we want to hear from you.NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, colour, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.\",\n",
       " 'country': 'UK',\n",
       " 'city': 'Reading',\n",
       " 'posted': '',\n",
       " 'header': 'EMEA Sales Leader Financial Services and Fintech at NVIDIA Corporation',\n",
       " 'company': 'NVIDIA Corporation',\n",
       " 'type': '',\n",
       " 'category': '',\n",
       " 'url': 'https://job-openings.monster.co.uk/monster/19e202bf-670a-4675-8faf-31f5291996bb'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfJob = MonsterScrap([\"Data Scientist\"],[\"UK\"])\n",
    "listOfJob[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to combine this list with those of other search engines in order to compose a data frame *(with pandas)*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
