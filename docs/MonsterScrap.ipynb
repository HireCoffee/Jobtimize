{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonsterScrap doc\n",
    "These functions allow to perform web scrapping on the Monster platform, to collect job detail.\n",
    "____\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Jobtimize.rotateproxies import RotateProxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get, Timeout\n",
    "from requests.exceptions import HTTPError, ProxyError\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import islice\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "from json import loads\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapBody()* function allows to take the body part of an html document from the URL.  \n",
    "This is to avoid redundant code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapBody(url, proxy = None):\n",
    "    with get(url, proxies = proxy) as response:\n",
    "        body = BeautifulSoup(response.text, 'html.parser').body\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *idFromLink()* function allows to extract the job ID from link.\n",
    "IDs come in two different forms:\n",
    "- A series of 9 numbers\n",
    "- A string of characters xxxxxxxxxx-xxxx-xxxx-xxxx-xxxxxx-xxxxxxxxxxxx\n",
    "\n",
    "Links on Monster come in 3 different forms: \n",
    "- Pages generated with ASP including the ID, composed only by 9 digits\n",
    "- The form \\*/monster/\\* with the ID, composed by string, which is the standard form for the main site\n",
    "- \"job offer\" *(in the language of the country)* with the ID in figures at the end, which is the standard form for each sub-sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idFromLink(link):\n",
    "    if \".aspx\" in link:\n",
    "        jobID = link[-14:-5]\n",
    "    elif \"/monster/\" in link:\n",
    "        jobID = re.findall(r'monster/.+?\\?', link)[0][8:-1]\n",
    "    else:\n",
    "        jobID = link[link.rfind('/')+1:]\n",
    "    return jobID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scrapMonsterID()` function extracts the *jobIDs* for each job and country from the search results provided by Monster.\n",
    "The [monster.co.uk](https://www.monster.co.uk/internationalJobs) site has access to the main master database, unlike the sub-sites which only have access to their own country the database.\n",
    "\n",
    "A query allows to have the total match if it exists. If there are more than 5000, the division *resultCountLabel* displays \"5000+\". If there is none, the division does not appear on the page.\n",
    "\n",
    "During the page browsing, $p$ greater than 1, the site has a behavior that displays the absence of results on a page $p$ while there are some on the page $p+1$ and therefore ignores the 20 results of the page $p$. The function counts it as an error.\n",
    "\n",
    "The absence of *resultCountLabel* is not interpreted as the end of the results unless the size of the list of jobs covered is equal to (or greater than) the match minus the number of jobs ignored by the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapMonsterID(searchList, countryList, prox = False):\n",
    "    setID = set()\n",
    "    for search in searchList:\n",
    "        search = search.replace(\" \",\"+\")\n",
    "        if prox: proxies = RotateProxies()\n",
    "        proxy = None\n",
    "        for country in countryList:\n",
    "            match = 5001\n",
    "            error = 0\n",
    "            listID = set()\n",
    "            page = 1\n",
    "            while True:\n",
    "                url = \"https://www.monster.co.uk/medley?q={}&fq=countryabbrev_s%3A{}&pg={}\".format(\n",
    "                    search, country, page)\n",
    "                if page % 50 == 0 and prox: proxy = proxies.next()\n",
    "                try:\n",
    "                    body = scrapBody(url, proxy)\n",
    "                except (Timeout, ProxyError):\n",
    "                    if prox:\n",
    "                        proxy = proxies.next()\n",
    "                        continue\n",
    "                    else:\n",
    "                        break\n",
    "                except HTTPError:\n",
    "                    break\n",
    "                else:\n",
    "                    if body.find(id=\"resultCountLabel\") is None:\n",
    "                        if len(listID) == 0:\n",
    "                            break\n",
    "                        else:\n",
    "                            error += 1\n",
    "                            if len(listID) >= (match - 20 * error):\n",
    "                                break\n",
    "                            else:\n",
    "                                page += 1\n",
    "                                continue\n",
    "                    else:\n",
    "                        match = int(\n",
    "                            re.sub(\n",
    "                                \"\\D\", \"\",\n",
    "                                body.find(\n",
    "                                    id=\"resultCountLabel\").text.split()[-1]))\n",
    "                        links = [\n",
    "                            link.a.attrs['href']\n",
    "                            for link in body.find_all(\"div\", class_=\"jobTitle\")\n",
    "                        ]\n",
    "                        listID = {idFromLink(link) for link in links}\n",
    "                        page += 1\n",
    "                setID = setID.union(listID)\n",
    "    return setID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dicoFromJson()* function normalizes the data of the request response. For a *jobID*, it collects information about the ad, the company and the specificities of the job in a dictionary.\n",
    "\n",
    "- description: long description\n",
    "- country: 2-letter abbreviation of the country\n",
    "- city: full city name\n",
    "- posted: job post creation date\n",
    "- header: post title\n",
    "- company: company name\n",
    "- type: type of employment contract (employee, intern...)\n",
    "- category: job category\n",
    "- url: post url redirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicoFromJson(args):\n",
    "    jobID, proxy = args\n",
    "    url = \"https://job-openings.monster.com/v2/job/pure-json-view?jobid={}\".format(\n",
    "        jobID)\n",
    "    try:\n",
    "        query = get(url, proxy).text\n",
    "    except HTTPError:\n",
    "        return {}\n",
    "    dico = loads(\n",
    "        normalize('NFKD', query).encode('ascii', 'ignore'))\n",
    "\n",
    "    general = ((\"description\", \"jobDescription\"),\n",
    "               (\"country\", \"jobLocationCountry\"),\n",
    "               (\"city\", \"jobLocationCity\"),\n",
    "               (\"posted\", \"postedDate\"))\n",
    "    company = ((\"header\", \"companyHeader\"),\n",
    "               (\"company\", \"name\"))\n",
    "    tracks = ((\"type\", \"eVar33\"),\n",
    "              (\"category\", \"eVar28\"))\n",
    "\n",
    "    ginfo, cinfo, tinfo = {}, {}, {}\n",
    "    for g in general:\n",
    "        try:\n",
    "            ginfo[g[0]] = normalize(\n",
    "                \"NFKD\",\n",
    "                \" \".join(BeautifulSoup(dico[g[1]], 'lxml').get_text().split()))\n",
    "        except KeyError:\n",
    "            ginfo[g[0]] = \"\"\n",
    "    for c in company:\n",
    "        try:\n",
    "            cinfo[c[0]] = BeautifulSoup(dico[\"companyInfo\"][c[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            cinfo[c[0]] = \"\"\n",
    "    for t in tracks:\n",
    "        try:\n",
    "            tinfo[t[0]] = BeautifulSoup(dico[\"adobeTrackingProperties\"][t[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            tinfo[t[0]] = \"\"\n",
    "    \n",
    "    dico = {**ginfo, **cinfo, **tinfo}\n",
    "    dico[\"url\"] = \"https://job-openings.monster.co.uk/monster/{}\".format(jobID)\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`MonsterScrap()`** is the main function which collects and standardizes data on the Monster site.  \n",
    "Threads are used depending on the size of the results for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonsterScrap(searchList, countryList, prox = False):\n",
    "    scraped = list()\n",
    "    setID = scrapMonsterID(searchList, countryList, prox)\n",
    "    if len(setID) < 20:\n",
    "        workers = len(setID)\n",
    "    else:\n",
    "        workers = len(setID) // 5\n",
    "    \n",
    "    if prox:\n",
    "        proxies = list(islice(RotateProxies().proxies, workers)) * len(setID)\n",
    "    else:\n",
    "        proxies = [None] * len(setID)\n",
    "    \n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        for result in executor.map(dicoFromJson, zip(setID, proxies)):\n",
    "            scraped.append(result)\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of use\n",
    "Let's do research on the data scientist post in the United Kingdom only.  \n",
    "Preview the 3rd item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Team Leader - Purification & Conjugation - (CAM-778587-99)Description About the roleAbcam, a rapidly expanding bioscience organisation, are looking for a Team Lead - Purification & Conjugation to join our first-class In-House Manufacturing team. This is a leadership role responsible for a team of Purification & Conjugation Technicians and Scientists. The successful candidate will be responsible for driving safety, quality, delivery, and cost thru leadership of the team.Roles and responsibilities:Support the Purification & Conjugation Team in-line with workload demands.Carry out weekly scheduling and monitoring of routine Purification and Conjugation processes and manage team workload.Support Technicians in their lab work, ensuring that all production work is carried out to high quality standards. Identify when specifications are missed and troubleshoot these situations.Keep stakeholders informed and up-to-date by sharing all relevant information and take part in cross team discussions, including presenting data to stakeholders and influencing outcomes through actions.Show compliance with Quality policies, SOPs and Health and Safety procedures.About youEssential:Hold a Life Science or Technical degreeDemonstrate a commitment to safety and reinforce safe behaviors with the staffAbility to work with and lead manufacturing teamsEnsure the accuracy of lab procedures and documentationHave at least three years experience of the practical and theoretical aspects of some/all of the following techniques:Antibody production techniquesProtein conjugationUse of AKTA chromatography systems - Unicorn method writing/ editingBe an enthusiastic team-player, with excellent written and verbal communication skills.Work well under pressure, working to tight deadlines.Demonstrate good troubleshooting skillsBe confident in using MS-Office applications.Desirable:Experience in chromatography techniques Affinity, SEC, IEX, HICExperience in protein stability formulation studies, including lyophilisation.Experience in Project ManagementExperience in working within an industrial environmentExperience in working to ISO 9001 standards.Experience with Lean and Six SigmaYou will be organised and enthusiastic and be comfortable with working autonomously or in a team environment. In addition to this you will have excellent interpersonal skills, be a competent user of MS Office applications and have a customer centric approach.If this sounds like you and youd like to be a part of a fast paced, growing business with the vision to become the most influential company and best-loved brand in life sciences please apply now! Primary Location: GB-GB-CambridgeJob: ManufacturingOrganization: UKSchedule: Regular StandardJob Type: Full-timeTravel: NoJob Posting: Oct 22, 2019, 12:57:06 PM',\n",
       " 'country': 'UK',\n",
       " 'city': 'Cambridge',\n",
       " 'posted': '',\n",
       " 'header': 'Team Leader - Purification & Conjugation at abcam',\n",
       " 'company': 'abcam',\n",
       " 'type': '',\n",
       " 'category': '',\n",
       " 'url': 'https://job-openings.monster.co.uk/monster/94fd35fc-918f-4ebe-9ff1-254411f51bab'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfJob = MonsterScrap([\"Data Scientist\"],[\"UK\"])\n",
    "listOfJob[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to combine this list with those of other search engines in order to compose a data frame *(with pandas)*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
