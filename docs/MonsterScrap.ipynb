{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MonsterScrap doc\n",
    "These functions allow to perform web scrapping on the Monster platform, to collect job detail.\n",
    "____\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, HTTPError\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "from json import loads\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapBody()* function allows to take the body part of an html document from the URL.  \n",
    "This is to avoid redundant code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapBody(url):\n",
    "    with urlopen(url) as response:\n",
    "        body = BeautifulSoup(response.read(), 'html.parser').body\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *idFromLink()* function allows to extract the job ID from link.\n",
    "IDs come in two different forms:\n",
    "- A series of 9 numbers\n",
    "- A string of characters xxxxxxxxxx-xxxx-xxxx-xxxx-xxxxxx-xxxxxxxxxxxx\n",
    "\n",
    "Links on Monster come in 3 different forms: \n",
    "- Pages generated with ASP including the ID, composed only by 9 digits\n",
    "- The form \\*/monster/\\* with the ID, composed by string, which is the standard form for the main site\n",
    "- \"job offer\" *(in the language of the country)* with the ID in figures at the end, which is the standard form for each sub-sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idFromLink(link):\n",
    "    if \".aspx\" in link:\n",
    "        jobID = link[-14:-5]\n",
    "    elif \"/monster/\" in link:\n",
    "        jobID = re.findall(r'monster/.+?\\?', link)[0][8:-1]\n",
    "    else:\n",
    "        jobID = link[link.rfind('/')+1:]\n",
    "    return jobID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _scrapMonsterID()_ function extracts the *jobIDs* for each job and country from the search results provided by Monster.\n",
    "The [monster.co.uk](https://www.monster.co.uk/internationalJobs) site has access to the main master database, unlike the sub-sites which only have access to their own country the database.\n",
    "\n",
    "A query allows to have the total match if it exists. If there are more than 5000, the division *resultCountLabel* displays \"5000+\". If there is none, the division does not appear on the page.\n",
    "\n",
    "During the page browsing, $p$ greater than 1, the site has a behavior that displays the absence of results on a page $p$ while there are some on the page $p+1$ and therefore ignores the 20 results of the page $p$. The function counts it as an error.\n",
    "\n",
    "The absence of *resultCountLabel* is not interpreted as the end of the results unless the size of the list of jobs covered is equal to (or greater than) the match minus the number of jobs ignored by the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapMonsterID(searchList, countryList):\n",
    "    setID = set()\n",
    "    for search in searchList:\n",
    "        search = search.replace(\" \",\"+\")\n",
    "        for country in countryList:\n",
    "            match = 5001\n",
    "            error = 0\n",
    "            listID = set()\n",
    "            page = 1\n",
    "            while True:\n",
    "                url = \"https://www.monster.co.uk/medley?q={}&fq=countryabbrev_s%3A{}&pg={}\".format(\n",
    "                    search, country, page)\n",
    "                try:\n",
    "                    body = scrapBody(url)\n",
    "                except HTTPError:\n",
    "                    break\n",
    "                else:\n",
    "                    if body.find(id=\"resultCountLabel\") is None:\n",
    "                        if len(listID) == 0:\n",
    "                            break\n",
    "                        else:\n",
    "                            error += 1\n",
    "                            if len(listID) >= (match - 20 * error):\n",
    "                                break\n",
    "                            else:\n",
    "                                page += 1\n",
    "                                continue\n",
    "                    else:\n",
    "                        match = int(\n",
    "                            re.sub(\n",
    "                                \"\\D\", \"\",\n",
    "                                body.find(\n",
    "                                    id=\"resultCountLabel\").text.split()[-1]))\n",
    "                        links = [\n",
    "                            link.a.attrs['href']\n",
    "                            for link in body.find_all(\"div\", class_=\"jobTitle\")\n",
    "                        ]\n",
    "                        listID = {idFromLink(link) for link in links}\n",
    "                        page += 1\n",
    "                setID = setID.union(listID)\n",
    "    return setID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dicoFromJson()* function normalizes the data of the request response. For a *jobID*, it collects information about the ad, the company and the specificities of the job in a dictionary.\n",
    "\n",
    "- description: long description\n",
    "- country: 2-letter abbreviation of the country\n",
    "- city: full city name\n",
    "- posted: job post creation date\n",
    "- header: post title\n",
    "- company: company name\n",
    "- type: type of employment contract (employee, intern...)\n",
    "- category: job category\n",
    "- url: post url redirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicoFromJson(jobID):\n",
    "    url = \"https://job-openings.monster.com/v2/job/pure-json-view?jobid={}\".format(\n",
    "        jobID)\n",
    "    try:\n",
    "        query = urlopen(url).read()\n",
    "    except HTTPError:\n",
    "        return {}\n",
    "    dico = json.loads(\n",
    "        normalize('NFKD', query.decode('utf-8')).encode('ascii', 'ignore'))\n",
    "\n",
    "    general = ((\"description\", \"jobDescription\"),\n",
    "               (\"country\", \"jobLocationCountry\"),\n",
    "               (\"city\", \"jobLocationCity\"),\n",
    "               (\"posted\", \"postedDate\"))\n",
    "    company = ((\"header\", \"companyHeader\"),\n",
    "               (\"company\", \"name\"))\n",
    "    tracks = ((\"type\", \"eVar33\"),\n",
    "              (\"category\", \"eVar28\"))\n",
    "\n",
    "    ginfo, cinfo, tinfo = {}, {}, {}\n",
    "    for g in general:\n",
    "        try:\n",
    "            ginfo[g[0]] = normalize(\n",
    "                \"NFKD\",\n",
    "                \" \".join(BeautifulSoup(dico[g[1]], 'lxml').get_text().split()))\n",
    "        except KeyError:\n",
    "            ginfo[g[0]] = \"\"\n",
    "    for c in company:\n",
    "        try:\n",
    "            cinfo[c[0]] = BeautifulSoup(dico[\"companyInfo\"][c[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            cinfo[c[0]] = \"\"\n",
    "    for t in tracks:\n",
    "        try:\n",
    "            tinfo[t[0]] = BeautifulSoup(dico[\"adobeTrackingProperties\"][t[1]],\n",
    "                                        'lxml').get_text().rstrip()\n",
    "        except KeyError:\n",
    "            tinfo[t[0]] = \"\"\n",
    "    \n",
    "    dico = {**ginfo, **cinfo, **tinfo}\n",
    "    dico[\"url\"] = \"https://job-openings.monster.co.uk/monster/{}\".format(jobID)\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MonsterScrap()** is the main function which collects and standardizes data on the Monster site.  \n",
    "Threads are used depending on the size of the results for data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonsterScrap(searchList, countryList):\n",
    "    scraped = list()\n",
    "    setID = scrapMonsterID(searchList, countryList)\n",
    "    if len(setID) < 20:\n",
    "        workers = len(setID)\n",
    "    else:\n",
    "        workers = len(setID) / 5\n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        for result in executor.map(dicoFromJson, setID):\n",
    "            scraped.append(result)\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of use\n",
    "Let's do research on the data scientist workstation in the United Kingdom only.  \n",
    "Preview the 6th item in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Role We are looking for a Deep Learning Engineer to join our AI Engineering team in Cambridge or Gothenburg. The ideal candidate will have industry experience developing and applying Machine Learning and Deep Learning solutions, e.g. developing data pre-processing pipelines, modelling, training state of the art deep neural networks (CNNs/RNNs/LSTMs/Transformers) as well as deploying inferencing pipelines to process unseen data at scale. The position will involve taking these skills and applying them to some of the most exciting data & prediction problems in drug discovery. You will work as part of a global team of deeply technical data scientists, knowledge engineers & machine learning engineers and have the chance to create tools that will advance the standard of healthcare improving the lives of millions of patients across the globe.We are working in collaboration with our scientists to help develop better drugs faster, choose the right treatment for a patient and run safer clinical trials. Our team empowers our scientists from early development to the late stages in drug development, driving innovation and acting as a catalyst for the adoption of the latest advances in Artificial Intelligence and Data Science. You will work closely with scientists & product teams and learn to deliver DL solutions at scale within the AstraZeneca tech stack, whilst encouraging best practices for DL across the company.We are looking for deep learning engineers capable of building robust, accurate DL-based systems and scientifically rigorous solutions that will be used across scientific units in AstraZeneca. As a strong software leader and an expert in building complex systems, you will be responsible for inventing how we use technology, Deep Learning and data to enable the productivity of AstraZeneca.You will help envision, build, deploy and develop our next generation of analytical engines at scale. #dataaiKey AccountabilitiesInvestigate innovative machine learning, artificial intelligence and statistic techniques for health data challenges.Collaborate with scientists and other machine learning engineers and data scientists to translate medical problems into machine learning problems.Design and implement machine learning pipelines.Design, implement and evaluate machine learning models solve problems faced by our drug development scientists, e.g., disease progression analysis in CT scans.Deploying machine learning solutions into production.Optimizing solutions for performance and scalability.Explain analyses and machine learning solutions to technical audiences.Liaise with other teams to enhance our technological stack, to enable the adoption of the latest advances in Data Processing and AI.Support the strategic planning of the team by providing leadership as well as mentor and support the team of engineers across multiple projects.Candidate Knowledge, Skills and ExperienceEssentialA PhD, in Computer Science, Applied Mathematics, Artificial Intelligence, Statistics or related subjects or Masters in a relevant discipline and exceptional Machine Learning skills.2+ years of experience and demonstrable deep technical skills in one or more of the following areas: machine learning, recommendation systems, pattern recognition, natural language processing or computer vision.1+ year of experience with one or more DL frameworks such as Tensorflow or PyTorch.Experience with scientific and machine learning libraries e.g., SciPy, Scikit-learn, NumPy.Strong software development skills. Proficiency in Python preferred.Experience building large scale data processing pipelines.Experience with Cloud computing, Hadoop/Spark, SQL.Ability to explain and present analyses and machine learning concepts to a broad audience.Ability to work with loosely defined objectives and turning these into concrete machine learning problems.Creative, collaborative, & product focused.DesirableExperience training and deploying machine learning models at scale on distributed cloud environmentsExperience applying machine learning in the healthcare domain.Experience with reinforcement learning is a plusOtherThe role will have no direct line reports, but task management responsibilities within project or services may occurDate Posted21-Nov-2019 Closing Date04-Dec-2019 AstraZeneca embraces diversity and equality of opportunity. We are committed to building an inclusive and diverse team representing all backgrounds, with as wide a range of perspectives as possible, and harnessing industry-leading skills. We believe that the more inclusive we are, the better our work will be. We welcome and consider applications to join our team from all qualified candidates, regardless of their characteristics. We comply with all applicable laws and regulations on non-discrimination in employment (and recruitment), as well as work authorization and employment eligibility verification requirements.',\n",
       " 'country': 'UK',\n",
       " 'city': 'Cambridge',\n",
       " 'posted': '2019-11-21T17:37:24',\n",
       " 'header': 'Engineer at astrazeneca',\n",
       " 'company': 'astrazeneca',\n",
       " 'type': '',\n",
       " 'category': '',\n",
       " 'url': 'https://job-openings.monster.co.uk/monster/e145f91b-7804-450c-a251-6d667e2933fa'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfJob = MonsterScrap([\"Data Scientist\"],[\"UK\"])\n",
    "listOfJob[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to combine this list with those of other search engines in order to compose a data frame *(with pandas)*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
