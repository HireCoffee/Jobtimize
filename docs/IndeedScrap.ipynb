{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndeedScrap doc\n",
    "These functions allow to perform web scrapping on Indeed platform, to collect job detail.\n",
    "____\n",
    "Requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, HTTPError\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapPage()* function allows to scrap an html document from the URL.  \n",
    "This is to avoid redundant code in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapPage(url):\n",
    "    with urlopen(url) as response:\n",
    "        page = BeautifulSoup(response.read(), 'html.parser')\n",
    "    return page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *scrapID()* function collects the IDs of the job ads published on the active page.  \n",
    "This information is the argument for the *'data-jk'* attribute in *'jobsearch-SerpJobCard'* class divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapID(page):\n",
    "    resultCol = page.find(id=\"resultsCol\")\n",
    "    setID = {\n",
    "        jobcard[\"data-jk\"]\n",
    "        for jobcard in resultCol.findAll(\"div\",\n",
    "                                         {\"class\": \"jobsearch-SerpJobCard\"})\n",
    "    }\n",
    "    return setID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *stripmatch()* function gets the match and the number of pages visited for the current search.  \n",
    "Since the form of a number in thousands differs from one country to another, regular expressions are used to harmonize the result: a list greater than two means a result greater than one thousand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripmatch(page):\n",
    "    try:\n",
    "        text = page.find(id=\"searchCountPages\").text.strip()\n",
    "    except AttributeError:\n",
    "        repage = match = None\n",
    "    else:\n",
    "        numlist = [num for num in re.findall(r'-?\\d+\\.?\\d*', text)]\n",
    "        repage = int(numlist[0])\n",
    "        if len(numlist) == 2:\n",
    "            match = int(numlist[1])\n",
    "        else:\n",
    "            match = int(''.join(numlist[1:]))\n",
    "    return repage, match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`scrapIndeedID()`** function extracts the IDs for each job for each country searched for.  \n",
    "The site is divided into different country-independent subdomains (the site in one country does not have access to the data in the other), scraping is performed for each subdomain of the site.  \n",
    "The number of results per page is arbitrarily set to 50.  \n",
    "After page 101 of results, Indeed considers the ads to be irrelevant. These will not be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapIndeedID(searchList, countryList):\n",
    "    setID = set()\n",
    "    for search in searchList:\n",
    "        search = search.replace(\" \", \"+\")\n",
    "        for country in countryList:\n",
    "            country = country.lower()\n",
    "            listID = set()\n",
    "            limit = 50\n",
    "            start = repage = count = 0\n",
    "            match = None\n",
    "            while (repage <= 101 or len(listID) < match):\n",
    "                url = \"https://{}.indeed.com/jobs?q={}&limit={}&start={}\".format(\n",
    "                    country, search, limit, start)\n",
    "                try:\n",
    "                    page = scrapPage(url)\n",
    "                except HTTPError:\n",
    "                    break\n",
    "                else:\n",
    "                    repage, match = stripmatch(page)\n",
    "                    count += 1\n",
    "                    if (match is None or repage < count):\n",
    "                        break\n",
    "                    else:\n",
    "                        listID = listID.union({(country, jobID)\n",
    "                                               for jobID in list(scrapID(page))\n",
    "                                               })\n",
    "                        start += limit\n",
    "            setID = setID.union(listID)\n",
    "    return setID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *dicoFromScrap()* function extracts the desired data from a tuple of the country and the *jobID*. A scraping is then performed for each page of a job. The collected information is:\n",
    "\n",
    "- description: long description\n",
    "- country: 2-letter abbreviation of the country in the tuple\n",
    "- city: full city name\n",
    "- posted: job post creation date, precise date for job published in the last 30 days\n",
    "- header: post title\n",
    "- company: company name\n",
    "- type\\*: type of employment contract (employee, intern...)\n",
    "- category\\*: job category\n",
    "- url: post url redirection\n",
    "\n",
    "\n",
    "\\* As the information is not formatted by most sub-domains, it will be extracted using word processing algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicoFromScrap(tupleID):\n",
    "    dico = {}\n",
    "    url = \"https://www.indeed.com/viewjob?jk={}\".format(tupleID[1])\n",
    "    try:\n",
    "        page = scrapPage(url)\n",
    "    except HTTPError:\n",
    "        return dico\n",
    "\n",
    "    def postedDate(page):\n",
    "        date = int(\n",
    "            re.findall(\n",
    "                r'-?\\d+\\.?\\d*',\n",
    "                page.find(\"div\", {\n",
    "                    \"class\": \"jobsearch-JobMetadataFooter\"\n",
    "                }).text)[0])\n",
    "        posted = (datetime.now() +\n",
    "                  timedelta(days=-date)).isoformat(timespec='seconds')\n",
    "        if date == 30: posted = \"+ \" + posted\n",
    "        return posted\n",
    "\n",
    "    dico[\"country\"] = tupleID[0].upper()\n",
    "    dico[\"url\"] = url\n",
    "    dico[\"description\"] = page.find(id=\"jobDescriptionText\").text\n",
    "    dico[\"header\"], dico[\"city\"], *_ = page.head.title.text.split(\" - \")\n",
    "    dico[\"company\"] = page.find(\"div\", {\"class\": \"icl-u-lg-mr--sm\"}).text\n",
    "    dico[\"type\"] = dico[\"category\"] = \"\"\n",
    "    dico[\"posted\"] = postedDate(page)\n",
    "\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 'FR',\n",
       " 'url': 'https://www.indeed.com/viewjob?jk=e84c3a7fa2589b2a',\n",
       " 'description': 'Vous êtes rattaché(e) à notre Business Analyst – Revenue Manager, et intégré(e) à l’équipe Marketing.\\nVos responsabilités\\nRépondre aux besoins des équipes métiers\\nVous participerez aux réunions préparatoires de création de nouveaux outils pour les équipes métiers\\nVous assisterez les équipes métiers dans la définition des indicateurs de performance (KPI) pertinents\\nCréation et amélioration des outils et rapports\\nVous travaillerez en étroite collaboration avec notre équipe Dévs pour utiliser notre base de données\\nVous serez force de proposition pour créer des tableaux de bord et études pour les différentes équipes métiers\\n\\nDurant votre stage, vous êtes encouragé(e) à vous investir sur les projets qui vous inspirent et à travailler en collaboration avec les autres équipes, pour créer des outils ou des nouvelles pratiques visant à l’amélioration du produit Zenpark.\\nProfil recherché\\nDe formation minimum bac+3, vous suivez une formation en école d’ingénieur ou informatique, une école de commerce ou université orienté mathématiques, statistiques ou data science. Vous souhaitez rejoindre une start-up en très forte croissance où vous pourrez pleinement vous investir et avoir une contribution réelle au développement de la société.\\nVous maîtrisez les outils et langages suivants :\\nExtraction de données (SQL)\\nVisualisation des données (Qlik Sense)\\nRestitution des données (PowerPoint, Javascript, VBA)\\nEventuellement, analyse de données et outils associés (R)\\n\\nTrès à l’aise avec les chiffres, curieux(se), et dynamique, vous êtes à la recherche d’un rôle vous permettant de mener à bien des missions à responsabilités multiples où vous pourrez rapidement développer vos compétences (analyse de données, compréhension des enjeux de différentes équipes métiers, prise de décision, etc.)\\nVotre organisation personnelle, votre esprit d’analyse et votre capacité à travailler de façon autonome assureront votre succès dans cette mission.\\nSi votre famille, vos amis, vos collègues, vous disent que vous êtes une « tête bien faite » et que vous-même le pensez aussi, et si en plus vous souhaitez farouchement vivre l’expérience de la startup, alors vous rassemblez les deux éléments qui vous rendent éligible à la Zenteam.\\nDéroulement des entretiens\\nUn entretien téléphonique de 30 min avec Marion Gauthier, Responsable Revenue & Data\\nUn test Excel\\nUn entretien physique ou visio avec un Développeur',\n",
       " 'header': 'Stagiaire Assistant(e) Data Analyst / Business Intelligence',\n",
       " 'city': 'Rennes (35)',\n",
       " 'company': 'Zenpark',\n",
       " 'type': '',\n",
       " 'category': '',\n",
       " 'posted': '2020-01-14T10:05:39'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicoFromScrap(('fr', 'e84c3a7fa2589b2a'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
